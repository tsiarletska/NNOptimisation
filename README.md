Lab, goal of which was the experiments with differenret oprimisators for CNN (used create model form [Machine Learning Mastery]([url](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/)), article "How to Develop a CNN for MNIST Handwritten Digit Classification" by Jason Brownlee. The data used - MNIST. 
The following optimisation algorithms were used: SGD, RMSProp, Adam, AdaGrad, AdaDelta (overall 31 experiment). Experiments were conducted based on chnage of optimisator, leaning rate and batch size. All results are stores in the excel file (both a table witha  summary and the results of eash model in a separate tab (tho, I sometimes forgot to note down the result,so there are some gaps). 
Assessment based on the following criterias: Mean accuracy, Mean stability metric, Mean Rate of Convergence	Mean Convergence Speed	Mean Initial Accuracy (First 5 Epochs)	Mean Mid Accuracy (Middle Epochs)	Mean Late Accuracy (Last 5 Epochs) (which were added to the model to fit the lab requirements).  As a visual representation were used graphs of loss and accuracy on train and test. 
